project_url,project_title,Deployment Type,Reason,Cloud
https://github.com/hnkovr/llm-rag-from-yt,YouTube Audio RAG Pipeline,"Batch, Web Service","The repository contains both batch processing components (Docker Compose services for worker, Dagster pipeline orchestrator) and web service components (FastAPI backend, Gradio UI, Nginx reverse proxy). The worker service handles batch ingestion while the API/UI services provide web-based access.",Other
https://github.com/cssaritama/RAG-Mental-Health-Assistant-Project,Mental Health Q&A System,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for the RAG mental health assistant. The Dockerfile and docker-compose.yml are configured to run this Streamlit app on port 8501, indicating it's deployed as a web service. While there are ingestion pipeline components, the primary deployment mechanism is the web service interface.",Unknown
https://github.com/zhibeky/quran_ai,Quran Semantic Search Engine,Web Service,"The repository contains a Telegram bot service (quran-bot) and a Streamlit dashboard, both serving as web interfaces for the Quran AI assistant. The docker-compose.yml shows these are deployed as web services with API endpoints.",Other
https://github.com/dvrk-dvys/ResidentRag,Hybrid Medical Search Pipeline,Web Service,"The repository contains a Streamlit application (app/main.py) that serves as a web interface for the medical AI assistant. The Dockerfile and docker-compose.yml are configured to run this Streamlit app as a web service on port 8501. The system architecture shows a user interacting with a Streamlit UI, which then routes requests through an LLM/agentic router to various data sources. This is clearly a web service deployment pattern, not batch processing or streaming.",Other
https://github.com/idalbo/fantasy_nba_advisor,AI Basketball Draft Advisor,Web Service,"The application is a Streamlit-based web service that serves fantasy basketball draft advice via a web interface. It uses Docker Compose to run a Streamlit server on port 8501, with a Qdrant vector database for data storage. The architecture is designed for serving ML-powered recommendations through a web UI, not for batch processing or streaming data pipelines.",Other
https://github.com/MonaHamid/Rag-Knowledge-Assiatant/tree/main,Hybrid Semantic Search Assistant,Web Service,"The repository contains a Streamlit application (app.py, app_monitoring.py) that serves as a web interface for the RAG knowledge assistant. The Dockerfile and docker-compose.yml are configured to run Streamlit on port 8501, exposing it as a web service. While there are ingestion components (dlt_ingest.py), the primary deployment is the Streamlit web application for user interaction.",Other
https://github.com/oleitao/llm-zoomcamp/tree/main/cohorts/2025/project,Elon Musk Tweet Chatbot,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for an AI chatbot. The Dockerfile and docker-compose.yml show it's containerized and exposes port 8501 for the Streamlit web service. While it includes OpenTelemetry monitoring components, the core deployment is a web service, not a streaming or batch system.",Other
https://github.com/mikitatryzno/smart-shopping-assistant,Georgian Supermarket Price Comparison,Web Service,"The repository contains a FastAPI server (src/api/main.py) and a Streamlit UI (src/app/streamlit_app.py) that serve the application via web interfaces. The code includes API endpoints, web server configuration, and UI components, indicating it's a web service deployment rather than batch processing or streaming.",Other
https://github.com/4-han/CIA,NITW Information Retrieval System,Web Service,"The repository contains a Dockerized Python application (main.py) that runs a Telegram bot using python-telegram-bot library. The bot is configured as a long-running service via Docker Compose with restart: always, and uses a web-based interface (Telegram API) for real-time conversational interactions. The presence of a Telegram bot container that depends on a database and serves user queries via API calls indicates a web service deployment pattern.",Other
https://github.com/NanGyeThote/Du-Won-Career-Pathfinder.git,AI Career Guidance Platform,Web Service,"The repository contains a FastAPI backend service (uvicorn server on port 8000) and React frontend (port 3000) deployed via Docker Compose. The backend provides REST APIs for career guidance, chatbot, CV analysis, and job search - all serving ML models and results via web endpoints. No streaming components (Kafka/Kinesis) or batch orchestrators (Airflow/Prefect) are present.",Other
https://github.com/Davidmide02/edrag-course-assistant-.git,AI-Powered Academic Tutor,Web Service,"The repository contains a Streamlit application (app.py) that serves as an interactive web interface for an AI-powered academic tutor. The Dockerfile and docker-compose.yml are configured to run this Streamlit app on port 8501, making it accessible as a web service. Streamlit is a web framework for building interactive applications, not a streaming data processing system.",Other
https://github.com/mcherif/plant-disease-rag-assistant,Plant Disease Diagnosis Assistant,Web Service,"The repository contains a FastAPI backend (src/interface/api.py) and a Streamlit UI (src/interface/streamlit_app.py) served via Docker containers. The docker-compose.yml defines two services: 'api' exposing port 8000 with uvicorn and 'ui' exposing port 8501 with streamlit. The codebase is structured as a web service providing plant disease diagnosis and RAG-powered Q&A through REST APIs and a web interface, not batch ETL jobs or streaming pipelines.",Other
https://github.com/oleitao/llm-zoomcamp/blob/main/cohorts/2025/project/README.md,Twitter History Q&A System,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for an AI chatbot. The Dockerfile and docker-compose.yml show it's containerized and exposes port 8501 for the Streamlit service. While there is an ETL scraper component, the primary deployment is the web service interface.",Other
https://github.com/marcelonieva7/AA_Bot,AA Documents Chatbot,Web Service,"The repository contains a FastAPI application (src.server.app:app) served via uvicorn, with Docker Compose configuration exposing port 8000. The code structure shows a web service architecture with API endpoints, HTML templates, and a chatbot interface - not batch ETL jobs or streaming message brokers.",Other
https://github.com/selamcode/scenematch-ai,Vector Search Movie System,"Batch, Web Service","The repository contains a data pipeline using DLT (Data Load Tool) for batch processing of movie data, and a Flask web application for serving the recommendation system. The DLT pipeline processes data in batches, while the Flask app provides a web service interface for the RAG system.",Other
https://github.com/wangjenn/selfcompassion-llm,Neurodiverse Self-Compassion AI Tool,Web Service,"The repository contains a Streamlit application (streamlit_app.py) that serves as an interactive web interface for self-compassion guidance. The Dockerfile and docker-compose.yml are configured to run this Streamlit app on port 8503, exposing it as a web service. Streamlit is a web framework for creating interactive applications, not a streaming data processing system.",Other
https://github.com/song2siren/llm-zoomcamp-music-theory-assistant,Music Theory RAG Assistant,"Batch, Web Service","The repository contains both batch and web service components. The batch component is evident from the ingest service in docker-compose.yml which runs once to load data into Qdrant (command: python ingest.py with restart: ""no""). The web service component is evident from the app service running Streamlit (port 8501) and the api service running FastAPI (port 8000), both serving the RAG application to users.",Other
https://github.com/Adityagurung/Brahman.ai,Hybrid Vector Search System,Web Service,"The repository contains a Streamlit application (app/app.py) served via Docker container on port 8501, with supporting services (Qdrant vector database, Ollama LLM, PostgreSQL) all orchestrated via docker-compose. This is a web service architecture for serving an AI travel assistant interface.",Other
https://github.com/Danodia-Rahul/Directors-cut-1.0,Film Techniques Knowledge Base,Web Service,"The repository contains a Streamlit application (ui/app.py) that serves as a web interface for querying and interacting with the film-making knowledge base. The main entry point is a Streamlit app that provides both chat and dashboard interfaces, which is characteristic of a Web Service deployment pattern.",Other
https://github.com/AlZrSe/zotero-llm,LLM Research Dashboard,Web Service,"The repository contains a Dockerized application with a Gradio web interface (port 7860) that serves LLM capabilities for Zotero research paper analysis. The main entrypoint runs a Python application that provides interactive querying capabilities, which is characteristic of a web service deployment.",Other
https://github.com/renelarsson/recipe-assistant,Recipe Data Pipeline,"Batch, Web Service","The repository contains both batch and web service components. The batch component is evident from the presence of ingestion pipelines using Prefect and DLT for scheduled ETL jobs, as well as custom Python scripts for data loading. The web service component is clear from the Flask API application that serves the Recipe Assistant functionality via HTTP endpoints, with Docker Compose configuration showing the app service exposing port 5000.",AWS
https://github.com/Marinazuzum/German-Payroll-Law-RAG-Assistant,German Payroll Law Assistant,Web Service,"The repository contains a Streamlit application (app/main.py) that serves as a web interface for the RAG assistant, along with a monitoring dashboard. The Docker configuration shows it runs as a web service on port 8501 using Streamlit's server functionality. While it includes batch processing capabilities for PDF ingestion, the primary deployment is as a web service.",Other
https://github.com/Abdelrahman-Adnan/medical-rag-assistant,AI Medical Question Answering,Web Service,"The repository contains a FastAPI application (src/api/main_api.py) and Streamlit interface (src/api/web_interface.py) served via Docker containers. The Dockerfile exposes ports 8000 (FastAPI) and 8501 (Streamlit), and the docker-compose.yaml defines an 'app' service that runs these web services. This is a web service deployment, not batch or streaming.",Other
https://github.com/bielacki/cinerag,Movie Recommendation RAG System,Web Service,"The repository contains a FastAPI backend (Dockerfile.api, app/main.py) serving a RESTful API on port 8000, and a Streamlit UI (Dockerfile.ui, ui/app.py) on port 8501. The docker-compose.yml shows these services running continuously to serve movie recommendations via web interfaces. While there are batch ingestion scripts (tmdb_ingest.py), the primary deployment is a web service architecture.",Other
https://github.com/sindhurauppu/k8s-assistant,Streamlit Interface for K8s Queries,Web Service,"The repository contains a Streamlit application (app.py) that serves as an interactive web interface for Kubernetes question answering. The docker-compose.yaml shows a streamlit service that runs on port 8501, providing a web-based UI for users to interact with the RAG system. This is clearly a web service deployment pattern rather than batch processing or streaming.",Other
https://github.com/sanchis135/LLM/tree/main/ModelOpsRAG,RAG Knowledge Base,Web Service,"The repository contains a Streamlit application (app/main.py) that serves as a RAG assistant interface, with Docker configuration for containerized deployment. The main entry point is a Streamlit app that runs as a web service on port 8501, providing an interactive UI for MLOps queries.",Other
https://github.com/Josesx506/llmzoomcamp-capstone/tree/main,Document Retrieval Augmented Generation,Web Service,"The repository contains a FastAPI backend service (app:app) and Next.js frontend, with Docker Compose orchestrating these web services. The FastAPI serves RAG responses via HTTP endpoints (/generate, /conversations, etc.), which is characteristic of a web service deployment pattern rather than batch or streaming.",Other
https://github.com/a920604a/llm-assistant,ArXiv Knowledge Retrieval Platform,"Batch, Web Service","The repository contains a Prefect pipeline (arxiv/prefect_entrypoint.py) that runs scheduled ETL jobs to fetch arXiv papers, process them, and build embeddings - this is a Batch component. It also includes FastAPI services (apiGateway) and frontend applications that serve ML models and results via API - this is a Web Service component. The architecture diagram shows both data ingestion pipelines and API layers.",Other
https://github.com/ynusinovich/environmental-health-agentic-rag,Vector Search Document System,"Batch, Web Service","The repository contains both batch processing components (data ingestion pipeline with Dockerfile.ingestion, Makefile commands for ingestion) and web service components (FastAPI backend, Streamlit frontend, multiple Dockerfiles for serving)",Other
https://github.com/lauraalexandria/movie_recommendation_chat,Movie Recommendation RAG System,Web Service,"The repository contains a FastAPI backend service (api/api.py) and Streamlit chat UI (ui/chatbot.py) that serve a RAG system for movie recommendations via web interfaces. The docker-compose.yaml shows containerized web services (FastAPI on port 8000, Streamlit on port 8501) that provide interactive chat functionality and monitoring dashboards.",Other
https://github.com/elena-andreini/AI-Sword-Sage,Japanese Blade RAG System,"Batch, Web Service","The repository contains a FastAPI web service (app/api) for serving RAG queries and a Prefect 3.x orchestration layer (app/flows, app/tasks) for batch processing workflows. The Dockerfile shows both FastAPI (port 4200) and Prefect (port 4201) are containerized together.",Other
https://github.com/rayluo88/llm-proj-zoomcamp,Unknown,Unknown,No files fetched,Unknown
https://github.com/ettysekhon/modern-wisdom-llm-native-pipeline,Modern Wisdom Podcast RAG Pipeline,"Batch, Web Service","The repository contains a batch processing pipeline for podcast data (RSS ingestion, transcription, chunking, embedding) and web services for API and UI (FastAPI, Chainlit). The Docker Compose setup shows both batch-like processing services and web service endpoints.",Other
https://github.com/martinid90/cs-chatbot-research-llm-zoomcamp,LLM-Enhanced Travel Support System,Web Service,The repository contains Dockerfiles and docker-compose configurations for two FastAPI services (llm_deploy and rag_deploy) that expose REST APIs on ports 5000 and 5001 respectively. Both services use uvicorn to run FastAPI applications that serve LLM inference and RAG functionality via HTTP endpoints.,AWS
https://github.com/tomekmatuszewski/pdf_research_assistant,Semantic Search System,Web Service,"The repository implements a web service architecture with a Streamlit frontend and FastAPI backend, serving PDF research assistant functionality via HTTP endpoints. The system uses Docker Compose to orchestrate multiple web services (frontend, backend, database, vector store) that communicate over network protocols.",Other
https://github.com/mag-mal/llm-zoomcamp-rag-project,Containerized Plant Advisor,Web Service,"The repository contains a Flask application (app:app) exposed on port 5000, with Docker Compose configuration for running the service. The main application is a RAG-powered chatbot that serves ML models via API endpoints, using Flask as the API interface. There are no workflow orchestrators, streaming components, or batch processing elements present.",Other
https://github.com/gmirandagh/knowledge-base-assistant,Multi-Language Knowledge Retrieval System,Web Service,"The repository contains a Flask-based web application (knowledge_base_assistant.app:app) served via Gunicorn on port 8000, with a Docker Compose setup that includes a web service container, PostgreSQL database, and Grafana monitoring. The application provides a conversational AI interface for querying technical documents through a web UI with real-time chat functionality.",Other
https://github.com/Gleekzone/multi-agent-tasting-assistant,AI Wine Tasting System,Web Service,"The repository contains a FastAPI application (app.main:app) served via uvicorn on port 8000, with Docker configuration for containerized deployment. The code structure shows a web service architecture with API endpoints, not batch processing or streaming components.",Other
https://github.com/aletbm/RAG_Research_Assistant,Semantic Research Search Engine,"Batch, Web Service",The repository contains both batch and web service components. The batch component is evident from the Prefect workflow orchestrator (pandas/ingestion_pipeline.py) and Docker Compose setup that runs ingestion pipelines conditionally. The web service component is shown by the FastAPI deployment (deployment.main:app) and Streamlit application (streamlit_app/app.py) that serve the RAG functionality via API endpoints.,GCP
https://github.com/valeqm/RAG-File-Assistant/tree/main,Local RAG Document Analyzer,Web Service,"The repository contains a Streamlit application (streamlit_app.py) that serves as a web interface for the RAG system, along with a monitoring dashboard (monitoring.py). The docker-compose.yaml shows these are deployed as web services on ports 8501 and 8502 respectively. Streamlit is a web service framework, not a streaming system.",Other
https://github.com/bkraffa/ds-interview-coach,AI Interview Coaching Platform,Web Service,"The repository contains a Streamlit application (streamlit_app.py) that serves as a web interface for the DS Interview Coach. The main deployment is via Streamlit for serving the RAG-based interview simulator, with supporting services like Qdrant (vector database) and PostgreSQL. While there are some evaluation scripts, the primary deployment is the web service interface.",Other
https://github.com/niting9881/llm-zoomcamp-project3,Python Package Documentation RAG System,Web Service,"The repository contains a FastAPI application (app.main) exposed on port 8000 and a Streamlit dashboard on port 8501, both serving as web services. The Dockerfile and docker-compose.yml show these services are containerized and exposed as web endpoints. There are no workflow orchestrators (Airflow, Prefect, etc.) for batch processing, nor streaming components (Kafka, Flink, etc.) present.",Other
https://github.com/dehaoterryzhang/ToSDR-RAG,Terms of Service RAG,"Batch, Web Service","The repository contains both a batch ingestion pipeline (Dockerfile.ingestion, data_ingestion.py, data_processing.py, chunking.py, embedding_generation.py) that processes data periodically and a web service component (Dockerfile.app, app_flask.py) that serves the RAG system via Flask API on port 5000. The docker-compose.yml orchestrates both services with the app depending on ingestion completion.",Other
https://github.com/villarrealfx/RAG-pdfs-docker,PDF Document Retrieval System,"Batch, Web Service",The project uses Airflow for batch processing of PDFs (scheduled DAGs) and FastAPI/Streamlit for serving the RAG API and web interface. Airflow orchestrates batch document ingestion while FastAPI provides real-time query endpoints and Streamlit serves as the web frontend.,Other
https://github.com/maxsg5/rag-system,Godot Documentation RAG System,Web Service,"The repository contains a docker-compose.yml with multiple web services (Ollama, Qdrant, Prometheus, Grafana, RAG metrics exporter) and requirements.txt includes FastAPI, Streamlit, and other web service frameworks. The system serves ML models via API endpoints and provides web-based interfaces for RAG functionality.",Other
https://github.com/suleyman-celik/LLM-RAG-Insurance-Assistant,Insurance Domain Knowledge Retrieval System,Web Service,"The repository contains a Flask API (app.py) and Streamlit dashboard, both serving ML models and RAG functionality via HTTP endpoints. The docker-compose.yaml shows services for an API server and web interface, with no streaming or batch orchestration components present.",Other
https://github.com/balajirags/ai-stylist,AI Fashion Product Discovery,"Batch, Web Service","The repository contains both a Prefect workflow (ingest_data_prefect.py) for batch ETL processing and a Flask API service (api/app.py) for serving recommendations. The batch component handles data ingestion into Qdrant, while the web service provides the AI Stylist interface.",Other
https://github.com/Howard233/recipe-rag-assistant/tree/main,Recipe Retrieval Assistant,Web Service,"The repository contains a FastAPI application (main.py, endpoints.py) that serves a RAG-based cooking assistant via API endpoints. The Dockerfile and docker-compose.yaml show it's containerized and exposes port 8000 for the FastAPI service. There are no workflow orchestrators, streaming components, or message brokers present.",Other
https://github.com/hmnguyen1067/Charles-Dicken-QA-chatbot,Charles Dickens Text Analysis,Web Service,"The repository implements a FastAPI backend (src/api/api.py) serving a QA chatbot API on port 8001, and a Streamlit chat UI (src/chat/app.py) on port 8501. Both are web services for interactive querying, not batch jobs or streaming pipelines.",Other
https://github.com/anicolas91/CitizenshipTest,USCIS Question Study System,Web Service,"The repository contains a Streamlit application (Home.py and pages/Dashboard.py) that serves as an interactive web-based chatbot for citizenship test preparation. The code shows a web service architecture with API endpoints for user interaction, not batch processing or streaming components.",Other
https://github.com/prantoran/Canada_law_rag_assistant,Law PDF Retrieval System,Web Service,"The repository contains a Streamlit application (main.py) that serves as a web interface for the RAG assistant, accessible via http://localhost:8501. The Dockerfile and docker-compose.yml are configured to run this as a web service with port 8501 exposed. While there is a monitoring dashboard and PDF processor, these are supporting services rather than streaming components - the core deployment is a web service interface.",Other
https://github.com/MuhammadShifa/medical-assistant-rag.git,Medical RAG Evaluation Framework,Web Service,"The repository contains a Streamlit application (main.py) that serves as a web interface for the medical RAG system. The code includes a Docker Compose setup with a web service component (Streamlit UI) and supporting services like Qdrant, PostgreSQL, and monitoring tools. The project is designed to provide an interactive web-based medical assistant rather than batch processing or streaming data pipelines.",Other
https://github.com/nupsea/book-mate,Multi-Book Analysis Platform,Web Service,"The repository contains a Gradio-based web application (src/ui/app.py) that serves an interactive UI for book chat and search. The Dockerfile exposes port 7860 (Gradio default) and the docker-compose.yml maps this to the host. The application runs continuously to serve user interactions, not as scheduled batch jobs or streaming data processing.",Other
https://github.com/Facco-Bruno/LLM_Talks_QA_Project#,Unknown,Unknown,No files fetched,Unknown
https://github.com/sheperd007/LLM-zoomcamp/tree/main/Final_Project#background,LLM Concepts and Applications,Web Service,"The repository contains a FastAPI application (app.py) that serves ML models via API endpoints, along with a Streamlit dashboard (dashboard.py) for visualization. These are web service components rather than batch or streaming systems.",Unknown
https://github.com/TimCosemans/PROJ-LLM-Zoomcamp,Multilingual Model Evaluation Framework,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for testing and evaluating LLM models. The Dockerfile and docker-compose.yaml show it's containerized and exposes port 8501 for the Streamlit app, which is a web service for ML model evaluation and testing.",Other
https://github.com/ssmangilev/llm-zoomcamp-project,Recipe Search RAG Pipeline,"Batch, Web Service",The project uses Prefect for batch data ingestion pipeline (orchestrated ETL) and FastAPI for serving the RAG application via web interface. The docker-compose shows both services running concurrently.,Other
https://github.com/celik-muhammed/LLM-RAG-Media-Assistant,Media Content Semantic Search,Web Service,"The repository contains a Flask API (app.py) serving RAG responses, a Streamlit chat app, and a CLI client. Dockerfile exposes port 5000 and runs Gunicorn to serve the Flask application. No batch orchestrators (Airflow/Prefect) or streaming components (Kafka/Flink) are present.",Other
https://github.com/niting9881/AIResearchAgent,Academic Literature RAG System,"Batch, Web Service","The repository contains Apache Airflow DAGs for automated data ingestion and processing (batch component) and a Streamlit application for serving the RAG interface (web service component). The Docker Compose setup includes both airflow-webserver and streamlit services, confirming both batch orchestration and web service deployment patterns.",Other
https://github.com/Kabalkina/baby_food_guide,AI Baby Nutrition Guide,Web Service,"The repository contains a Flask API (app.py) that serves as a web service interface, along with Docker containerization for deployment. The application exposes endpoints on port 5000 and uses a web-based architecture with a frontend interface.",Other
https://github.com/Deljimae/energy-analytics-rag,Global Power Plant Analytics,Web Service,"The repository contains a Flask application (app.py) that exposes an API endpoint for querying energy data using natural language. The application is containerized with Docker and uses Docker Compose to orchestrate services including the Flask app, PostgreSQL database, and Grafana. The primary deployment artifact is a web service that responds to HTTP requests, not scheduled batch jobs or streaming data pipelines.",Other
https://github.com/HagerAhmed/Musafir,Conversational Travel Search Platform,Web Service,"The repository contains a Streamlit application (app.py) served via Docker and docker-compose, with a web interface exposed on port 8501. The architecture includes a web service layer (Streamlit) that depends on backend services (Elasticsearch, PostgreSQL) but does not implement batch workflows or streaming pipelines.",Other
https://github.com/VeraTorka/nutrition-assistant,Nutrition Facts Chatbot,Web Service,"The repository contains a Flask application (app.py) that serves as a REST API for a nutrition chatbot. The Dockerfile exposes port 5000 and runs gunicorn to serve the Flask app. The docker-compose.yaml maps port 5000 to the host, indicating this is a web service deployment. While Grafana is included for visualization, it's not the primary ML service - the Flask app is the main web service component.",Other
https://github.com/nathadriele/credit-decision-LLM-RAG-platform,Credit Decision Platform,Batch,"The repository contains a complete MLOps platform with Airflow DAGs for orchestrating credit decision workflows, dbt models for data transformation, and scheduled ETL pipelines. The infrastructure includes EKS for container orchestration and RDS for data storage, indicating batch-oriented data processing rather than real-time streaming or web service deployment.",AWS
https://github.com/Rachel0619/VanTrails/tree/main,Vancouver Trail Metadata Filtering,Web Service,"The repository contains a Flask API service (vantrails-api) and a Gradio UI service (vantrails-ui) that serve the RAG application via HTTP endpoints. The Docker Compose configuration shows these services expose ports 8000 and 7860 respectively, indicating web service deployment rather than batch or streaming processing.",Other
https://github.com/lucapug/chat-with-my-notes,Document Retrieval Analytics Platform,Web Service,"The repository contains a FastAPI backend (pyproject.toml shows FastAPI dependency) serving a RAG system with a web interface (README mentions ""Web Interface"" and ""Responsive chat UI""). The architecture shows a FastAPI Backend handling user requests, document processing, and LLM interactions, indicating this is a web service that serves ML models and results via API.",Other
https://github.com/teighanmiller/HorizonZeroDawn_RAG,Game Wiki RAG System,Web Service,"The repository contains a Streamlit app (src/app.py) that serves as an interactive frontend for a Retrieval-Augmented Generation (RAG) system. The Docker Compose configuration shows a web service architecture with the app exposed on port 8501, and the README confirms this is a web-based question-answering interface accessible via browser at http://localhost:8501. While there are data ingestion components, the primary deployment pattern is a web service for user interaction.",Other
https://github.com/vanbastun/ffs_rag,Hybrid Retrieval Fantasy Football System,Web Service,"The repository contains a FastAPI application (src/api/main.py) that serves a RAG pipeline via HTTP endpoints. The Docker configuration and docker-compose file show it's designed to run as a web service on port 8000 with API endpoints for querying. There are no workflow orchestrators, message brokers, or streaming components present.",Other
https://github.com/nupsea/content-pal,Streaming Content Evaluation Suite,Web Service,"The repository contains a Flask API (src/modules/workflow/app.py) that serves search functionality via HTTP endpoints, with Docker configuration for containerized deployment. The architecture shows a web service pattern with Streamlit UI, Flask API backend, and PostgreSQL logging - all characteristic of a web service deployment rather than batch or streaming processing.",Other
https://github.com/Zainab-Omn/Slack_FAQ,Vector Search Slack Discussions,Web Service,"The repository contains a Streamlit application (app.py) served via Docker Compose on port 8501, with a Dockerfile and docker-compose.yml defining the web service infrastructure. The app provides an interactive UI for asking questions and receiving AI-generated answers, which is characteristic of a web service deployment.",Other
https://github.com/sancyb/PawfectMate,Dog Breed Matchmaker,Web Service,"The repository contains a FastAPI application (app.py) that serves as an API endpoint for a Retrieval-Augmented Generation (RAG) application. The Dockerfile exposes port 5000 and runs uvicorn to serve the FastAPI app. The docker-compose.yaml shows the app service running on port 5000, confirming this is a web service deployment.",Other
https://github.com/educapel/Health-Care-Assistant,Medical Entity Annotation System,Web Service,"The repository contains a Flask application (app:app) served via gunicorn in Docker, with a frontend React app, indicating a web service architecture. The Dockerfile and docker-compose setup show the application is designed to run as a web service on port 8000/5050, not as batch jobs or streaming pipelines.",Other
https://github.com/lkirch/ScienceSage,Space Exploration Q&A System,Web Service,"The repository contains a Streamlit app (app.py) and FastAPI service (rag_api.py) that serve the RAG system via web interfaces. The Dockerfile exposes ports 8501 (Streamlit) and 8000 (FastAPI), and the Makefile includes commands to run both web services. While there are data processing scripts, the primary deployment is as a web service for user interaction.",Other
https://github.com/bobbykim89/LLM-Project-LOTR,Middle-earth Semantic Search,Web Service,"The repository contains a Django REST Framework backend API and a Nuxt.js frontend application, both deployed as web services on Vercel. The system provides a conversational chat interface for character lookups, which is a web service use case rather than batch processing or streaming.",Other
https://github.com/iliasstefanidis/TheParrotLibrary,Unknown,Unknown,No files fetched,Unknown
https://github.com/ajbuzik/travel_assitant,Travel Recommendation RAG Demo,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for a travel assistant. The Dockerfile and docker-compose.yml show it's deployed as a web service on port 8501. Streamlit is a web framework for building interactive applications, not a streaming processing system.",Other
https://github.com/Tejanshu9/LegalMind,Legal Justice System Dashboard,Web Service,"The repository contains a Streamlit application (app.py) that serves as the main entry point for the LegalMind AI assistant. The application provides an interactive web interface for users to query legal information, and the docker-compose.yml shows it's containerized for deployment. This is a classic web service architecture serving ML/AI capabilities via a web interface.",Other
https://github.com/techwithcosta/youtube-rag-submission,Unknown,Unknown,No files fetched,Unknown
https://github.com/jesusoviedo/lus-laboris-py,Paraguay Labor Code RAG,Web Service,"The repository contains a FastAPI application (main.py, app/ directory) that serves a RAG system for Paraguay's Labor Code via API endpoints. The code shows a web service architecture with API routes for querying legal documents, health checks, and OpenAPI documentation. There are no workflow orchestrators, streaming components, or batch processing infrastructure visible in the codebase.",GCP
https://github.com/Deathslayer89/documind,Technical Document Intelligence System,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for document Q&A, with a Dockerfile exposing port 8501 and docker-compose configuration for running the service. The application uses LangChain for RAG pipeline processing and provides API endpoints for user interaction, which is characteristic of a web service deployment rather than batch or streaming processing.",Other
https://github.com/zainalabdeen/llm-zoomcamp/tree/main/customer-support,Customer Support RAG System,Web Service,"The repository contains a Streamlit application (main.py, frontend/app.py) that serves a customer support RAG system via web interface on ports 8501 (user app) and 8502 (dashboard). The Dockerfile and docker-compose.yml are configured to run this as a web service, not as batch jobs or streaming processing.",Other
https://github.com/alperugurca/playground/tree/main/llm_2025_project1,Learning Through Coding Experiments,Unknown,"The repository contains only a README.md file with no actual code, configuration files, or project structure that would indicate the deployment type (Batch, Web Service, or Streaming).",Unknown
https://github.com/sanchis135/LLM/tree/main/RAG_Occupational_Risk_Prevention,Risk Prevention Document Search,Web Service,"The repository contains a Streamlit application (app/ui_streamlit/Home.py) that serves as a web interface for interactive queries with an LLM. The Dockerfile and docker-compose.yml are configured to run this Streamlit app as a web service on port 8501. While there are ingestion and evaluation scripts, the primary deployment mechanism is the Streamlit web service.",Other
https://github.com/Mannerow/ubuntu-rag,Ubuntu Support RAG Assistant,"Batch, Web Service","The project includes a Streamlit web service for customer support chat (streamlit_app.py) and a Prefect orchestration pipeline (docker_setup_flow.py) for batch data processing and ingestion. The Streamlit app serves ML-powered responses via web interface, while Prefect manages scheduled/triggered batch jobs for data preprocessing and Elasticsearch indexing.",Other
https://github.com/NotYetBenGan/LLMZoomCamp/blob/main/Project/README.md,Qdrant Event Retrieval System,Web Service,"The repository contains a Dockerfile and docker-compose.yml that builds and runs a Streamlit application (scripts/app_streamlit.py) on port 8501. Streamlit is a web framework for creating interactive web applications, and the Docker configuration shows this is deployed as a web service. The project description confirms this is an ""interactive application"" with a ""Streamlit-based user interface"" for users to interact through a web application.",Other
https://github.com/Harunscodes/supermarket-rag-assistant,Retail Policy Retrieval System,Web Service,"The repository implements a CLI interface (run_agent.py) that serves an RAG agent via Ollama API calls, using Flask/FastAPI-like patterns for model serving. The code shows a service-oriented architecture where the agent responds to user queries in real-time, retrieving from Qdrant and Neo4j, then generating responses via Ollama. This is characteristic of a Web Service deployment pattern rather than batch or streaming.",Other
https://github.com/eadka/fridgechef,Vegetarian Recipe Recommendation Engine,Web Service,"The repository contains a Flask API (app.py) that serves recipe recommendations via HTTP endpoints, and is containerized with Docker/Docker Compose. The Streamlit UI is a visualization layer that consumes this API. There are no workflow orchestrators, batch schedulers, or streaming components like Kafka/Flink present.",Other
https://github.com/V4siliy/llm-manpage-rag/releases/tag/v0.1.0-alpha,Linux Man-Page Semantic Search,Web Service,"The repository contains a Django web application with Docker Compose setup for serving ML models and RAG capabilities via API endpoints. The main service is a Django application running on port 8000 with nginx reverse proxy, designed to serve search and Q&A functionality through web interfaces and RESTful APIs.",Other
https://github.com/Flow791/ScoutRAG,Football Stats Semantic Search,Web Service,"The repository contains a Gradio web application (`src/gradio_app.py`) that serves as a web interface for the football scouting assistant. The application is launched via `python run_app.py` and exposes a web UI on port 7860. The code shows a web service architecture with a frontend interface for user interaction, not batch processing or streaming components.",Other
https://github.com/rafaelladuarte/avesrag-assistant,Cerrado Biome Bird Search,Web Service,"The repository contains a Streamlit application (app/ directory with requirements.txt and Dockerfile) that serves an interactive bird identification assistant via a web interface on port 8501. The docker-compose.yml shows the app service exposing port 8501, confirming it's a web service. Streamlit is used for ML inference/assistant functionality, not for streaming data processing.",Other
https://github.com/nikhilj9/AWS-RAG-Assistant,AWS Bedrock Knowledge Assistant,Web Service,"The repository contains a Flask-based API (app.py) that serves a RAG assistant via REST endpoints (/question, /health). The Dockerfile and docker-compose.yml show it's designed to run as a web service container exposing port 5000/5001, not as batch jobs or streaming pipelines.",AWS
https://github.com/naivebird/job-matching-assistant#,Unknown,Unknown,No files fetched,Unknown
https://github.com/twu13/TrialGPT,Qdrant-Powered Trial Retrieval,Web Service,"The repository contains a Streamlit application (app/main.py) that serves as a web interface for querying clinical trials. The Dockerfile and docker-compose.yml are configured to run this Streamlit app as a web service on port 8501. While there are ingest/evaluation components, the primary deployment is the Streamlit web service for user interaction.",Other
https://github.com/razorcd/llm-project,Courier Support Agent RAG System,Web Service,"The repository contains a Flask application (app.py) that serves as an API server for a conversational AI agent. The Dockerfile exposes port 9696 and runs a Flask app, and docker-compose.yml shows the app service listening on ports 5000 and 9696. The application provides real-time conversational capabilities via API endpoints, which is characteristic of a Web Service deployment.",Other
https://github.com/Cabetico/project-rag,E-commerce Customer Support Chatbot,Web Service,"The repository contains a Flask API (e_commerce_rag/app.py) that serves a RAG-based chatbot, exposed on port 8000, and a Streamlit frontend on port 8501. Dockerfiles and docker-compose configurations show it's deployed as web services, not batch jobs or streaming pipelines.",Other
https://github.com/tanhtra/cookery-rag,Culinary Knowledge Retrieval System,Web Service,"The repository contains a Streamlit application (appcore.py) served via Docker container on port 8501, with Dockerfile and docker-compose.yml configurations for containerized web deployment. Streamlit is a web service framework for serving interactive applications.",Other
https://github.com/krish-rm/market-master-trading-decision-agent,Market Data Analysis Pipeline,Web Service,"The repository contains a Streamlit application (app/streamlit_app.py) that serves the trading decision agent via a web interface. The Dockerfile and docker-compose.yml are configured to run this Streamlit app on port 8501, indicating it's deployed as a web service for interactive market analysis and trading guidance.",Other
https://github.com/shayansm2/askhn/,Agentic RAG Search System,Web Service,"The repository contains a Go-based API server (cmd/api) and a React UI (ui/) that communicate via HTTP endpoints. The system exposes a REST API on port 8080 and a web interface on port 5173, with Docker Compose orchestrating these services. While Temporal workflows are used for orchestration, the primary deployment pattern is serving ML-powered RAG responses through web services rather than batch ETL or streaming data pipelines.",Other
https://github.com/clementlwm94/ziweidoushu,Chinese Astrology Chart Retrieval System,Web Service,"The repository contains a FastAPI application (`rag_api.py`) that serves a web UI and API endpoints for Zi Wei Dou Shu analysis. The code uses FastAPI to collect user input (birth details and questions) and return generated responses, which is characteristic of a web service deployment. There are no workflow orchestrators, scheduled jobs, or message brokers indicating batch or streaming patterns.",Other
https://github.com/gsenseless/tg_job_RAG,Job-Resume Matching System,Web Service,"The repository contains a Streamlit application (main.py) that serves as a web interface for job-resume matching. The Dockerfile and docker-compose.yml are configured to run this Streamlit app as a web service on port 8501, with health checks and external access. This is a web service deployment, not batch processing or streaming.",GCP
https://github.com/SapientSapiens/capstoneproject-2025-llmz,Survival Content RAG System,Web Service,"The repository contains two FastAPI services (rag/rag_service_serve.py) and a Streamlit app (interface_app/app.py) that are containerized and deployed as web services. The docker-compose.yml shows these services running on ports 8010 and 8501 respectively, with health checks and API endpoints. There are no workflow orchestrators, message brokers, or streaming components present.",Other
https://github.com/educapel/Fitness-assistant,Fitness Exercise Database,Web Service,"The repository contains a Flask application (app.py) that serves as a web service API for fitness assistance. It exposes REST endpoints for exercise search, chat, and feedback. The Dockerfile and docker-compose.yaml are configured to run this Flask app with Gunicorn web server, exposing port 8000. There are no workflow orchestrators (Airflow, Prefect), message brokers (Kafka, Kinesis), or streaming components present.",Other
https://github.com/Dcwind/llm-job-assistant,Career Insights Knowledge Base,Web Service,"The application is a Streamlit-based web interface (runs on port 8501) that serves as an interactive dashboard for job posting analysis. The Dockerfile and docker-compose.yml both expose port 8501 and run Streamlit as the main service, indicating this is a web service rather than batch or streaming processing.",Other
https://github.com/selesselvan/food-recipe-zoomcamp,Food Recipe Vector Database,Web Service,"The repository contains a Streamlit application (app.py) served via Docker container on port 8501, with Dockerfile and docker-compose.yml configurations for running the web service. Streamlit is a web framework for serving interactive applications, not batch processing or streaming.",Other
https://github.com/wingylui/LLMzoomcamp/tree/main,BakeBuddy Recipe Retrieval System,Web Service,"The repository contains a Streamlit application (streamlit_app.py) that serves as an interactive web interface for recipe search and feedback collection. The Dockerfile is configured to run this Streamlit app on port 8501, and docker-compose.yaml exposes it at http://localhost:8501. This is a classic web service deployment pattern where the application is served via HTTP endpoints for user interaction.",Other
https://github.com/Xue-Zhiming-Bruce/LLM-Zoomcamp-RAG-Project,Multilingual Podcast Retrieval System,Web Service,"The repository contains a FastAPI backend that serves a Retrieval-Augmented Generation (RAG) application via HTTP endpoints (e.g., /api/chat, /api/search, /api/health). The Dockerfile and docker-compose.yml are configured to run the FastAPI service, and the frontend is a static UI that interacts with this API. There are no workflow orchestrators, scheduled ETL jobs, or streaming components present.",Other
https://github.com/Erfan-ghiyasvand/Stardew-RAG-Farmhand,Wiki Content Search Engine,"Batch, Web Service","The repository contains a Streamlit web service (app.py) for user interaction with the RAG system, and a comprehensive data processing pipeline that includes web scraping, content processing, and vectorization - indicating batch processing of the Stardew Valley wiki content. The README mentions automated web scraping and ETL-like operations for building the knowledge base.",Other
https://github.com/rajindermavi/ScienceMadeEasy,Mathematical Research Retrieval System,"Batch, Web Service","The repository contains a batch ETL pipeline (run_etl.py) that processes ArXiv papers and indexes them, and a web service component (Streamlit app.py) that serves the RAG interface to users. The ETL pipeline runs scheduled jobs to fetch and process papers, while the Streamlit application provides a web-based interface for querying the indexed documents.",Other
https://github.com/Jaykold/llmzoomcamp-project,SQuAD RAG Chat Application,Web Service,"The repository contains a Streamlit application (app/app.py) that serves a RAG chat interface via web, with Docker Compose orchestrating the web service on port 8501. The application exposes an interactive web interface for question-answering, not batch ETL jobs or streaming data pipelines.",Other
https://github.com/glk08909/smart-travel-planner,Travel Knowledge Base Engine,Web Service,"The repository contains a Streamlit application (smart-travel-planner/planner/app.py) that serves as a web interface for travel planning, along with Docker configuration for containerization. The docker-compose.yml shows services exposing ports 8501 (Streamlit) and 3000, indicating web service deployment rather than batch or streaming processing.",Other
https://github.com/michaeljohnilagan/aspragers,Autism Spectrum Information Engine,Batch,"The repository contains a chatbot application that processes static data (PubMed abstracts) stored in CSV files. The application uses Docker for containerization and includes functionality to refresh data periodically via scripts, but there is no evidence of real-time streaming components (Kafka, Kinesis) or web service APIs (Flask, FastAPI). The data processing appears to be batch-oriented with scheduled updates to the dataset.",Other
https://github.com/yeoyingxin/travel-recommendations-japan,Reddit Travel Content Pipeline,Web Service,"The repository contains a Dockerfile and app.py that runs a Dash web application (a Python web framework) with Flask backend. The Dockerfile shows the app is started with ""python -u app.py --host=0.0.0.0"", indicating it's a web service. The code uses Qdrant for vector search and OpenAI for LLM responses, serving recommendations via a web interface. This is not a batch ETL job or streaming system.",Other
https://github.com/data-tomic/llm-zoomcamp/tree/main/06-project,Medical Document Processing Pipeline,"Batch, Web Service","The repository contains a scheduled ETL Kubernetes Job for data processing (Batch) and an Open WebUI service for user interaction (Web Service). The ETL job runs periodically to fetch, stage, chunk, embed, and load data, while the RAG pipeline serves real-time user queries via a web interface.",Other
https://github.com/wgb-10/dtc-book-archive-qa-system,Book Archive Q&A System,Web Service,"The repository contains a Streamlit application (streamlit>=1.50.0) that serves as a chatbot interface for querying the Book of the Week archive. The code structure shows this is a web-based application with a UI for user interaction, not a batch ETL job or streaming system.",Unknown
https://github.com/MohamedMostafa259/pif-multimodal-rag,Vector-Based Report Retrieval System,Web Service,"The repository contains a FastAPI backend (src/main.py) serving RAG endpoints (/api/v1/answer, /api/v1/compare) with a React frontend, plus Celery workers for background tasks. This is a classic web service architecture with API endpoints for interactive querying, not batch processing or streaming.",Other
https://github.com/ivano666/arizona-desert-plants-chat,Arizona Desert Plant Guide,Web Service,"The repository contains a FastAPI application (app.py) served via uvicorn in Docker, with a Dockerfile and docker-compose.yml defining the service. This is a classic web service deployment pattern for serving ML/RAG applications via REST API.",Other
https://github.com/freillat/FinReportingLLM,Financial Data RAG Pipeline,Web Service,"The repository contains a Streamlit application (app.py) served via Docker on port 8501, with a Docker Compose setup that defines an 'app' service exposing this web interface. The ingestion component is a one-time data preparation step, not a continuous deployment pattern.",Other
https://github.com/paty-oliveira/ai-assistant-self-employers-pt,Multilingual Government Guide,Web Service,"The repository contains a FastAPI backend (src/api.py) and a Streamlit frontend (app.py) that serve an AI assistant via web interfaces. The backend exposes API endpoints for chat requests, and the frontend provides an interactive web interface. Both components are containerized with Docker and designed to run as web services.",Other
https://github.com/zainalabdeen/llm-zoomcamp/tree/main/hr_assistant,Bilingual HR Legal Advisor,Web Service,"The repository contains a Streamlit application (app.py) that serves as an interactive web interface for the HR assistant. The app.py file shows a Streamlit-based web service that loads documents, creates vector embeddings, and provides a chat interface for users to ask questions about Saudi labor law. This is a web service deployment pattern where the application is served via Streamlit's web framework.",Unknown
https://github.com/bekarizz/llm-zoomcamp-project/tree/main,Industrial Database Natural Language Query,Web Service,"The project uses FastAPI (requirements.txt) and Docker Compose to serve a web application with APIs for natural language to SQL query generation. The architecture includes PostgreSQL, Qdrant, and Ollama services exposed via ports, indicating a web service deployment rather than batch or streaming.",Other
https://github.com/PK109/customer_support_rag_system,Customer Support Knowledge Base,"Batch, Web Service","The repository contains a batch processing pipeline for PDF ingestion (Makefile orchestrates sequential steps: download, convert, chunk, embed) and a Streamlit web service for interactive chat with the RAG system. The batch pipeline processes documents offline, while Streamlit provides a web-based UI for querying the knowledge base.",Other
https://github.com/Ye-Bhone-Lin/educational-tutor-ai,Vector Search Document Analyzer,Web Service,"The repository contains a Streamlit application (streamlit_app.py) that serves an AI-powered document Q&A interface via a web-based UI. The app runs continuously to handle user interactions, document uploads, and real-time question answering, which is characteristic of a web service deployment rather than batch or streaming processing.",Other
https://github.com/christos-golsouzidis/Infrang,Knowledge Base Retrieval System,Web Service,"The repository contains a FastAPI application (infrang-api.py) that exposes REST endpoints for information retrieval and generation. The Dockerfile shows it runs uvicorn to serve the API on port 7456, indicating it's a web service deployment.",Other
https://github.com/Dkaattae/Public-Filings-Chat-Bot-RAG,SEC Filings RAG Analytics,"Batch, Web Service","The repository contains batch ETL pipelines using dlt (data load tool) for scheduled data loading from S3 to Qdrant and from Yahoo Finance to DuckDB, plus a Streamlit web service for the chat interface. The pipelines are orchestrated as batch jobs, while Streamlit serves the RAG chat application.",AWS
https://github.com/kimoz1994/DIY_Home_Improvement_Assisstant,Home Improvement Video Assistant,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for a DIY Home Improvement Assistant. The Dockerfile shows it's containerized and exposes port 8501, which is the default Streamlit port. The README explicitly states it's a ""simple Streamlit user interface"" that allows users to submit questions and receive responses from a local LLM, which is characteristic of a web service deployment.",Other
https://github.com/belaz19/llm-explore-Norway,Norway Tourist Guide RAG,Web Service,"The project uses Docker Compose to deploy a Streamlit application that serves as a web interface for a RAG-based tourist guide. The Dockerfile and docker-compose.yml show a containerized web service running on port 8501, with Streamlit as the web framework for serving the application.",Other
https://github.com/michailmitsakis/fantasy-book-assistant,Book Metadata Chatbot Assistant,Web Service,"The repository contains a Streamlit UI (app.py) that serves as an interactive web interface for querying a book assistant. The project is designed to run as a web service where users can interact with the application through a browser, making it a Web Service deployment rather than batch processing or streaming.",Other
https://github.com/Maxkaizo/g_poke_t,Pokmon Knowledge Retrieval System,"Batch, Web Service","The repository contains a batch pipeline orchestrated via Makefile that runs ETL jobs (data ingestion, normalization, indexing) and a Streamlit web service for the RAG interface. The pipeline is not streaming-based.",Other
https://github.com/thefl0ur/dtc-llm-zoomcamp-project/,Local Cooking Advisor,Web Service,"The project uses docker-compose to run a local LLM server (llama.cpp), Qdrant vector database, and MongoDB. It provides a conversational AI interface for cooking advice via RAG system. The main components are web services: llama.cpp server on port 8080, Qdrant on port 6333, and MongoDB on port 27017. There are no workflow orchestrators, streaming message brokers, or scheduled batch jobs visible in the code.",Other
https://github.com/Gilliography/llm-zoomcamp/tree/main/Athletics%20Agent,Athletics Agent LLM Pipeline,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for an athletics agent, allowing users to interact with LLM-powered functionality through a web UI. This is a web service deployment pattern.",Unknown
https://github.com/JoshPola96/AIAssistantHub-LangGraph,RAG-Based Q&A System,Web Service,"The repository contains a Streamlit application (app.py) that serves as an interactive web interface for the AI assistant. The README explicitly states ""Streamlit: For the interactive web application frontend"" and provides instructions to run ""streamlit run app.py"". This is a web service deployment pattern, not batch processing or streaming.",Other
https://github.com/Nicosm1988/Project_1_rag-history-argentina,Historical Document Retrieval System,Web Service,"The repository contains a FastAPI backend (app.api) that serves a RAG system via API endpoints, with a frontend interface built using HTML/CSS/JavaScript. The code structure shows a web service architecture with API endpoints for processing queries and serving responses, not batch or streaming components.",Other
https://github.com/bekarizz/llm-zoomcamp-project,Industrial Database Natural Language Query,Web Service,The repository contains a FastAPI application (fastapi==0.115.0) and uses Docker Compose to orchestrate services including a web interface (Adminer) and likely an API service. The code structure with test.py and build_index.py suggests a web service that serves ML-generated SQL queries via API endpoints.,Other
https://github.com/Ye-Bhone-Lin/Myanmar-Cultural-Heritage-Q-A-System,Myanmar Heritage Knowledge Base,Web Service,"The repository contains a FastAPI backend (main.py) and Streamlit frontend, both serving as web services. The Dockerfile shows the application is containerized and runs uvicorn to serve the FastAPI application on port 8000. There are no workflow orchestrators, streaming components, or batch processing elements present.",Unknown
https://github.com/clicksuku/SundarkpCode/tree/master/LLM%20Zoomcamp%202025%20Project,Olist Commerce Data Pipeline,Batch,"The repository contains a Data Engineering Zoomcamp Capstone Project using MAGE AI, which is a workflow orchestrator for batch ETL jobs. The project includes Terraform configurations and BigQuery usage, indicating scheduled data processing workflows rather than real-time streaming or web service deployment.",GCP
https://github.com/A-n-i-e/Ask-Mama-Put,Ask Mama Put Culinary Guide,Web Service,"The repository contains a FastAPI backend (main.py) and React frontend served via Docker containers, with uvicorn as the ASGI server. The architecture is a web service with API endpoints for user queries and responses, not batch ETL jobs or streaming data pipelines.",Other
https://github.com/mavcr/quizmate,AI Quiz Generator Pipeline,Web Service,"The application is a Spring Boot-based web service that exposes REST APIs for quiz generation and evaluation. It uses a web server architecture with controllers, services, and database integration, designed to serve ML-generated content via HTTP endpoints.",Other
https://github.com/baozh166/2025_llm,Semantic Medical Question Answering,Batch,"The repository implements a Retrieval-Augmented Generation (RAG) pipeline with vector database operations. The code shows batch-oriented workflows: ingest_vec.py loads and processes CSV data in bulk, embeds text, and uploads to Qdrant database. The main.py and run_test.sh demonstrate one-off query execution rather than continuous streaming or web service deployment. No streaming components (Kafka, Flink) or web service frameworks (Flask, FastAPI) are present.",Other
https://github.com/Saheed388/mediquest_project_full_code,AI Healthcare Recommendation Engine,Web Service,"The repository contains a FastAPI backend (main.py) that serves an AI-powered healthcare recommendation tool via API endpoints. The Dockerfile shows it runs uvicorn to serve the FastAPI application on port 8000, which is characteristic of a web service deployment pattern.",GCP
https://github.com/gkumarg/agentic_rag_streamlit/,Vector Database Knowledge Search,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for an agentic RAG chat application. The code shows a web service that provides interactive chat functionality through a web browser interface, with the main entry point being `streamlit run agentic_rag_streamlit/app.py`.",Other
https://github.com/ardnahh6/scholar-assistant,Vector Search Research Tool,Web Service,"The repository contains a Streamlit-based application (app/interface.py) that serves as a web interface for uploading PDFs, processing them, and querying via a natural language interface. The code structure shows a web service architecture with Streamlit for the UI, LangChain for document processing, and Ollama for local LLM inference.",Other
https://github.com/kachiann/nursing-mothers-rag-chatbot,Infant Care RAG System,Web Service,"The repository contains a Streamlit application (rag_chatbot_app.py) that serves a conversational AI chatbot via a web interface. The code shows a real-time RAG pipeline with semantic search that responds to user queries, which is characteristic of a web service deployment rather than batch processing or streaming.",Other
https://github.com/akumawavez/LLMzoomcamp2025/tree/main/cohorts/2025/project/AI_NutritionLabel_Explainer,Large Language Model Training Repository,Web Service,"The repository contains a Streamlit application (app.py) that serves an LLM-powered chat interface for nutrition label analysis. The code shows a web-based UI with API endpoints for user interaction, model inference, and RAG functionality - all characteristic of a web service deployment.",Unknown
https://github.com/jhuff-genomics/llm-project-research-assistant,PDF Research Assistant,Web Service,"The repository contains a FastAPI-based web service that serves as a research assistant interface. The code shows a web server container that handles user queries via HTTP endpoints (both web UI and curl API calls), with the main application logic implemented as a FastAPI app. The system is deployed as serverless containers on Modal Labs, which is a cloud container service for web services.",AWS
https://github.com/KrishnaG-101/AI-Healthcare-Assistant,Unknown,Unknown,No files fetched,Unknown
https://github.com/akumawavez/LLMzoomcamp2025/tree/main/cohorts/2025/project/attempt2,Local Real Estate LLM,Web Service,"The repository contains a Streamlit application (ChatApp_RAG_ollama_langchain.py) that serves as a web interface for a conversational chatbot. The code includes requirements for Streamlit and the README shows running ""streamlit run ChatApp_RAG_ollama_langchain.py"", indicating this is a web service deployment.",Other
https://github.com/KrishnaG-101/AI-Medical-Expert,AI Medical Encyclopedia Chatbot,Web Service,"The repository contains a FastAPI backend server (uvicorn main:app) and a Streamlit frontend (streamlit run app.py) that serve an AI medical chatbot via web interfaces. The code shows API endpoints for document parsing and LLM calls, indicating a web service architecture rather than batch or streaming processing.",Other
https://github.com/alexchugunoff/marketplace-seller-agent,Marketplace Seller Assistant,Web Service,"The repository contains a Streamlit application (app.py) that serves as a web interface for the marketplace seller assistant agent. The Dockerfile and docker-compose.yml are configured to run this Streamlit app on port 8501, indicating it's deployed as a web service for user interaction.",Other
